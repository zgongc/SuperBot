# =============================================================================
# modules/simple_train/configs/training.yaml
# AI Training Configuration - Supervised Learning
# =============================================================================

version: "1.0"
description: "AI that learns strategy - Entry Filter + Exit Management"

# =============================================================================
# SERVER SETTINGS
# =============================================================================
server:
  host: "0.0.0.0"
  port: 8100
  workers: 1                          # Single worker for GPU
  reload: false
  debug: false

# =============================================================================
# DEVICE SETTINGS
# =============================================================================
device:
  # GPU/CPU selection (auto, cuda, cpu)
  type: "auto"

  # Models to be loaded initially
  preload:
    - BTCUSDT

  # Checkpoint directory
  checkpoints_dir: "data/ai/checkpoints/simple_train"
  rejected_dir: "data/ai/rejected/simple_train"

  # Default model
  default_model: "BTCUSDT"

# =============================================================================
# DATA
# =============================================================================
data:
  # Data source
  source: "parquet"                   # parquet, csv, database
  parquet_path: "data/parquets"       # Uses ParquetsEngine

  strategy: "simple_rsi"

  # Time range
  start_date: "2025-01-05"
  end_date: "2025-03-30"

  # Symbols
  symbols:
    - "BTCUSDT"
    # - "ETHUSDT"
    # - "BNBUSDT"

  # Timeframe
  timeframe: "5m,15m,30m"

  # Warmup bars (for indicator calculation)
  warmup_bars: 200

# =============================================================================
# ENVIRONMENT (Backtest Simulation)
# =============================================================================
environment:
  initial_balance: 10000

  # Trading maliyetleri (Binance Futures)
  commission: 0.0004                  # %0.04 taker fee
  slippage: 0.0001                    # %0.01

  # Position sizing
  max_position_size: 0.3              # Max %30 position
  min_position_size: 0.1              # Min %10 position

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
model:
  # Lookback window - How many bars will the model look back?
  lookback_window: 100                # ~8 hours in 5m

  # Forecast horizon - null = until the trade closes
  forecast_horizon: null

  # Label creation
  labeling:
    method: "trade_result"            # trade_result, price_change, bucketed
    # Trade result: Wait until TP/SL/Timeout

# =============================================================================
# ENTRY MODEL
# =============================================================================
entry_model:
  enabled: true
  type: "xgboost"                     # xgboost, lightgbm, lstm, transformer

  # Operating mode
  mode: "filter"                      # filter, direction, both

  filter:
    enabled: true
    # Filter the strategy signal: "open" / "enable"
    threshold: 0.5                    # If confidence > 0.5, then open
    require_match: true               # AI and strategy must be aligned

  direction:
    enabled: true
    # Direction suggestion independent of strategy: "LONG" / "SHORT" / "HOLD"

  # XGBoost parameters
  xgboost:
    n_estimators: 100  # More than 100 trees
    max_depth: 6  # Greater than 6 (more complex decision)
    learning_rate: 0.05  # Slower but more careful learning
    subsample: 0.8
    colsample_bytree: 0.8

  # LightGBM parameters (if type is lightgbm)
  lightgbm:
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
    num_leaves: 31
    subsample: 0.8

  # LSTM parameters (if type is lstm)
  lstm:
    hidden_size: 128
    num_layers: 2
    dropout: 0.2
    bidirectional: false

# =============================================================================
# EXIT MODEL
# =============================================================================
exit_model:
  enabled: true
  type: "xgboost"                        # xgboost, lstm

  # Output parameters estimation
  predict_params:
    tp_percent: true                  # Predict the TP percentage
    be_trigger: true                  # BE trigger point
    trailing_start: true              # Trailing start point
    partial_exits: false              # Partial exit levels (advanced)

  # TP/SL limits
  constraints:
    min_tp_percent: 0.5               # Minimum %0.5 TP
    max_tp_percent: 20.0              # Maximum %20 TP
    min_sl_percent: 0.3               # Minimum %0.3 SL
    max_sl_percent: 10.0              # Maximum %10 SL

  # Exit profiles (can be used as a constant instead of a model)
  profiles:
    aggressive:
      tp_percent: 10.0
      sl_percent: 5.0
      be_trigger: null                # BE does not exist
      trailing_start: 8.0
    balanced:
      tp_percent: 6.0
      sl_percent: 3.0
      be_trigger: 2.0
      trailing_start: 4.0
    conservative:
      tp_percent: 4.0
      sl_percent: 2.0
      be_trigger: 1.0
      trailing_start: 2.0

  # Default profile (if the model is disabled)
  default_profile: "balanced"

  # LSTM parameters (for the exit model)
  lstm:
    hidden_size: 64
    num_layers: 2
    dropout: 0.2

# =============================================================================
# TRAINING STRATEGY
# =============================================================================
training:
  # Training strategy
  strategy: "iterative"               # sequential, iterative

  iterative:
    max_rounds: 3
    convergence_threshold: 0.01       # Stop if PnL change < %1
    freeze_after_convergence: true

  # Train/Val/Test split
  split:
    method: "time_based"              # time_based, random, walk_forward
    train_ratio: 0.7
    val_ratio: 0.15
    test_ratio: 0.15

    # For walk-forward
    walk_forward:
      n_folds: 5
      gap_bars: 100                   # Space between train/validation sets

  # Hyperparameter optimization
  optimization:
    enabled: false
    method: "optuna"                  # optuna, grid_search
    n_trials: 50
    metric: "sharpe_ratio"            # sharpe_ratio, total_return, win_rate

# =============================================================================
# ADAPTATION (Online Learning)
# =============================================================================
adaptation:
  enabled: false                      # Currently disabled

  online_learning:
    enabled: false
    update_frequency: "daily"         # daily, weekly, on_performance_drop
    min_new_samples: 50

  meta_learning:
    enabled: false
    method: "maml"                    # maml, reptile
    adaptation_steps: 5

# =============================================================================
# EVALUATION
# =============================================================================
evaluation:
  # Evaluation frequency
  eval_freq: 10000                    # Her N sample'da evaluation

  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "sharpe_ratio"
    - "total_return"
    - "max_drawdown"
    - "win_rate"
    - "profit_factor"

  # Success criteria
  success_criteria:
    min_sharpe: 1.5
    max_drawdown: 0.25
    min_win_rate: 0.55
    min_profit_factor: 1.3

# =============================================================================
# INFERENCE CONFIG
# =============================================================================
inference:
  # Batch processing
  batch_size: 32

  # Caching
  cache_enabled: true
  cache_ttl: 60                       # 60 seconds cache

  # Fallback
  fallback_action: "HOLD"             # In case of error, HOLD

  # Timeout
  prediction_timeout: 5.0             # 5 seconds timeout

# =============================================================================
# CHECKPOINTS & LOGGING
# =============================================================================
checkpoints:
  save_path: "data/ai/checkpoints/simple_train"
  save_freq: 50000
  save_best: true
  keep_last: 3

logging:
  level: "INFO"
  tensorboard: true
  log_path: "logs/simple_train"
  log_predictions: false              # Log every prediction
  log_features: false                 # Log feature extraction

# =============================================================================
# EARLY STOPPING
# =============================================================================
early_stopping:
  enabled: true
  patience: 10                        # Stop if the evaluation gets worse 10 times
  min_delta: 0.01                     # Minimum improvement
  metric: "sharpe_ratio"              # The metric to be tracked
