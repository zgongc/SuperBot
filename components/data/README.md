# components/data - Data Management Layer

**SuperBot Data Layer** - Veri indirme, saklama ve yÃ¶netim bileÅŸenleri

---

## ğŸ“‹ Genel BakÄ±ÅŸ

Bu dizin SuperBot'un tÃ¼m veri yÃ¶netim operasyonlarÄ±nÄ± iÃ§erir:
- **Database Management:** SQLite/PostgreSQL veri saklama
- **Historical Data:** Parquet-based geÃ§miÅŸ OHLCV verisi
- **Data Download:** Exchange'lerden veri indirme
- **Timeframe Resampling:** Alt timeframe'den Ã¼st timeframe oluÅŸturma

---

## ğŸ“ Dosyalar

### 1. **database_engine.py** â†’ `core/database_engine.py`
**Sorumluluk:** Database connection management

**Ã–zellikler:**
- âœ… SQLite/PostgreSQL dual backend (config-driven)
- âœ… Async SQLAlchemy 2.0 engine
- âœ… Connection pooling
- âœ… Session factory
- âœ… Auto table creation
- âœ… Health check
- âœ… Graceful shutdown

**KullanÄ±m:**
```python
from core.database_engine import DatabaseEngine

db = DatabaseEngine(config, logger)
await db.initialize()

async with db.get_session() as session:
    result = await session.execute(query)

await db.shutdown()
```

**Config:** `config/infrastructure.yaml` â†’ `database` bÃ¶lÃ¼mÃ¼

---

### 2. **database_models.py**
**Sorumluluk:** SQLAlchemy ORM model tanÄ±mlarÄ±

**Ã–zellikler:**
- âœ… SQLAlchemy `Base` class
- â³ Model'lar ihtiyaca gÃ¶re eklenecek (ÅŸu an 0 tablo)

**KullanÄ±m:**
```python
from components.data.database_models import Base
from sqlalchemy import Column, Integer, String, Float

# Yeni model ekle
class Candle(Base):
    __tablename__ = "candles"
    id = Column(Integer, primary_key=True)
    symbol = Column(String(20), nullable=False)
    timestamp = Column(Integer, nullable=False)
    open = Column(Float)
    high = Column(Float)
    low = Column(Float)
    close = Column(Float)
    volume = Column(Float)
```

**Not:** Tablo ekledikten sonra DatabaseEngine otomatik oluÅŸturur.

---

### 3. **database_manager.py**
**Sorumluluk:** DatabaseEngine facade - unified API

**Ã–zellikler:**
- âœ… DatabaseEngine wrapper
- âœ… Session context manager
- âœ… Health check proxy
- âœ… Singleton pattern
- â³ CRUD methodlarÄ± ihtiyaca gÃ¶re eklenecek (ÅŸu an YOK)

**KullanÄ±m:**
```python
from components.data.database_manager import get_database_manager

dm = get_database_manager()
await dm.initialize()

# Custom query
async with dm.get_session() as session:
    result = await session.execute(select(Model).where(...))

# Health check
is_healthy = await dm.health_check()

await dm.shutdown()
```

**Singleton:** `get_database_manager()` global instance dÃ¶ner

**Gelecek CRUD Ã¶rnekleri:**
```python
# Ä°htiyaÃ§ olunca eklenecek:
await dm.save_candle(candle_data)
candles = await dm.get_candles(symbol, timeframe, limit=100)
await dm.save_trade(trade_data)
trades = await dm.get_open_trades()
```

---

### 4. **historical_data_manager.py**
**Sorumluluk:** Historical OHLCV data management (Parquet-based)

**Ã–zellikler:**
- âœ… Multi-backend: Parquet/SQLite/PostgreSQL/CSV
- âœ… Smart incremental updates (duplicate prevention)
- âœ… Date range filtering
- âœ… Data validation & cleaning
- âœ… Cache management
- âœ… Integration with data_downloader.py

**KullanÄ±m:**
```python
from components.data.historical_data_manager import HistoricalDataManager

hdm = HistoricalDataManager(config, logger)

# Load historical data
df = await hdm.load_data(
    symbol='BTCUSDT',
    timeframe='1m',
    start_date='2025-01-01',
    end_date=None  # BugÃ¼ne kadar
)

# Update data (incremental)
await hdm.update_data(
    symbol='BTCUSDT',
    timeframes=['1m', '5m']
)

# Get info
info = hdm.get_data_info('BTCUSDT')
```

**Veri KaynaÄŸÄ±:** Parquet files (`data/parquets/`)

**Use Cases:**
- Backtest Module (historical data loading)
- AI Training (feature engineering data)
- Analysis (indicator calculations)

---

### 5. **data_downloader.py**
**Sorumluluk:** Exchange'lerden historical data indirme

**Ã–zellikler:**
- âœ… Binance API integration
- âœ… All timeframes support (1m â†’ 1M)
- âœ… Smart incremental update (son timestamp'ten devam)
- âœ… Duplicate detection & removal
- âœ… Parquet save
- âœ… Progress tracking

**KullanÄ±m:**
```python
from components.data.data_downloader import DataDownloader

downloader = DataDownloader()

# Ä°lk download
await downloader.download(
    symbol='BTCUSDT',
    timeframe='1m',
    start_date='2025-01-01',
    output_dir='data/parquets'
)

# Update (incremental)
await downloader.update(
    symbol='BTCUSDT',
    timeframe='1m',
    output_dir='data/parquets'
)
```

**Output:** Parquet files
- Format: `BTCUSDT_1m_2025.parquet`

**Dependencies:** `python-binance`, `pandas`, `pyarrow`

---

### 6. **timeframe_resampler.py**
**Sorumluluk:** Alt timeframe â†’ Ã¼st timeframe dÃ¶nÃ¼ÅŸÃ¼mÃ¼

**Ã–zellikler:**
- âœ… Smart source selection (en yakÄ±n alt timeframe)
- âœ… OHLCV aggregation (pandas resample)
- âœ… File naming with `_re` suffix
- âœ… Volume summation
- âœ… Validation

**KullanÄ±m:**
```python
from components.data.timeframe_resampler import TimeframeResampler

resampler = TimeframeResampler(data_dir='data/parquets')

# 1m â†’ 2h resample
df_2h = resampler.resample(
    symbol='BTCUSDT',
    target_tf='2h',
    year=2025
)
```

**Output:** Resampled parquet files
- Format: `BTCUSDT_2h_2025_re1m.parquet` (1m'den resample edildi)

**Use Cases:**
- Missing timeframe data (2h, 3h, 6h, 8h, 3d)
- Backtest optimization (daha az data)

**Resample Hierarchy:**
- 3m â†’ 1m
- 2h â†’ 1h
- 6h â†’ 4h, 2h, 1h
- 8h â†’ 4h, 2h, 1h
- 3d â†’ 1d

---

## ğŸ—‚ï¸ Veri AkÄ±ÅŸÄ±

### Historical Data Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Exchange (Binance) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data_downloader.py â”‚  â† Download/Update historical data
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parquet Files      â”‚  â† data/parquets/BTCUSDT_1m_2025.parquet
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  â”‚ timeframe_resampler.py   â”‚  â† 1m â†’ 2h, 3h, etc.
           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚             â†“
           â”œâ†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  â”‚ Resampled Parquet Files  â”‚
           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ historical_data_manager.py  â”‚  â† Unified data loader
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ†’ Backtest Module
           â”œâ†’ AI Training Module
           â””â†’ Analysis Module
```

### Real-time Data Pipeline (Gelecek)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WebSocket Stream   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database (SQLite)  â”‚  â† database_manager.py
â”‚  LiveKlineBuffer    â”‚     (live candles before archiving)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ†’ Trading Engine (real-time)
           â”‚
           â””â†’ Archive to Parquet (daily/weekly)
```

---

## ğŸ¯ Database vs Parquet

### Database (SQLite/PostgreSQL)
**AmaÃ§:** Real-time operational data

**Use Cases:**
- Live trading data (positions, orders, trades)
- WebUI dashboard (recent data)
- Real-time monitoring
- Session tracking

**Avantajlar:**
- Fast queries (indexed)
- Transactional
- Relational (foreign keys)

**Dezavantajlar:**
- Limited size (SQLite)
- Slower for bulk analytics

---

### Parquet Files
**AmaÃ§:** Historical bulk data storage

**Use Cases:**
- Backtest data (years of OHLCV)
- AI training datasets
- Analytics & indicators
- Long-term archival

**Avantajlar:**
- Compressed (snappy)
- Fast columnar reads
- Unlimited size
- Portable

**Dezavantajlar:**
- No updates (immutable)
- No relations
- File-based queries

---

## ğŸš€ KullanÄ±m SenaryolarÄ±

### Senaryo 1: Backtest iÃ§in Data HazÄ±rlama
```python
# 1. Download historical data
downloader = DataDownloader()
await downloader.download('BTCUSDT', '1m', start_date='2024-01-01')

# 2. Resample to higher timeframe (eÄŸer lazÄ±msa)
resampler = TimeframeResampler()
df_1h = resampler.resample('BTCUSDT', '1h', year=2024)

# 3. Load for backtest
hdm = HistoricalDataManager(config, logger)
df = await hdm.load_data('BTCUSDT', '1m', start_date='2024-01-01')

# 4. Run backtest
# ...
```

### Senaryo 2: Live Trading Data Kaydetme (Gelecek)
```python
# DatabaseManager kullanÄ±lacak
dm = get_database_manager()
await dm.initialize()

# Real-time candle kaydet
await dm.save_candle({
    "symbol": "BTCUSDT",
    "timeframe": "1m",
    "timestamp": 1700000000000,
    "open": 50000,
    "high": 50100,
    "low": 49900,
    "close": 50050,
    "volume": 100.5
})

# Trade kaydet
await dm.save_trade({
    "symbol": "BTCUSDT",
    "side": "LONG",
    "entry_price": 50000,
    "quantity": 0.1,
    # ...
})
```

### Senaryo 3: WebUI Dashboard Data (Gelecek)
```python
# Recent trades
trades = await dm.get_trades(limit=50)

# Open positions
positions = await dm.get_open_positions()

# Portfolio balance
balance = await dm.get_latest_balance()
```

---

## ğŸ“Š Dosya Organizasyonu

```
components/data/
â”œâ”€â”€ database_models.py          # SQLAlchemy Base + Models (ihtiyaca gÃ¶re eklenecek)
â”œâ”€â”€ database_manager.py         # DatabaseEngine facade (ihtiyaca gÃ¶re CRUD eklenecek)
â”œâ”€â”€ historical_data_manager.py  # Parquet-based historical data loader
â”œâ”€â”€ data_downloader.py          # Binance historical data downloader
â”œâ”€â”€ timeframe_resampler.py      # Timeframe resampling (1m â†’ 2h, etc.)
â””â”€â”€ README.md                   # Bu dosya

core/
â””â”€â”€ database_engine.py          # Database connection manager
```

---

## ğŸ”§ Configuration

**Config:** `config/infrastructure.yaml`

```yaml
database:
  backend: "sqlite"  # sqlite, postgresql

  sqlite:
    path: "data/database/superbot.db"
    timeout: 30
    check_same_thread: false
    wal_mode: true
    pool_size: 5
    max_overflow: 10

  postgresql:
    host: "${POSTGRES_HOST}"
    port: "${POSTGRES_PORT}"
    database: "${POSTGRES_DB}"
    user: "${POSTGRES_USER}"
    password: "${POSTGRES_PASSWORD}"
    pool_size: 10
    max_overflow: 20
```

---

## âš¡ Ä°lk KullanÄ±m

### 1. Database Setup
```python
from components.data.database_manager import get_database_manager

dm = get_database_manager()
await dm.initialize()  # Database + tables oluÅŸturulur

# Health check
is_healthy = await dm.health_check()
```

### 2. Historical Data Download
```python
from components.data.data_downloader import DataDownloader

downloader = DataDownloader()
await downloader.download('BTCUSDT', '1m', start_date='2024-01-01')
# â†’ data/parquets/BTCUSDT_1m_2024.parquet
```

### 3. Load Historical Data
```python
from components.data.historical_data_manager import HistoricalDataManager

hdm = HistoricalDataManager(config, logger)
df = await hdm.load_data('BTCUSDT', '1m', start_date='2024-01-01')
# â†’ pandas DataFrame (OHLCV)
```

---

## ğŸ¯ GeliÅŸme PlanÄ±

### Phase 1: Base Infrastructure âœ…
- [x] DatabaseEngine (core/database_engine.py)
- [x] Base class (database_models.py)
- [x] DatabaseManager facade (database_manager.py)
- [x] Historical data (historical_data_manager.py)
- [x] Data downloader (data_downloader.py)
- [x] Timeframe resampler (timeframe_resampler.py)

### Phase 2: Model'lar (Ä°htiyaca GÃ¶re)
Ä°lk ihtiyaÃ§: **WebUI Portfolio Module**
- [ ] ExchangeSymbol model (symbol listesi)
- [ ] SymbolFavorite model (kullanÄ±cÄ± favorileri)
- [ ] Portfolio model (portfolio tanÄ±mlarÄ±)
- [ ] PortfolioPosition model (portfolio pozisyonlarÄ±)
- [ ] Corresponding CRUD methods

**Backtest Module ihtiyacÄ±:**
- [ ] BacktestRun model
- [ ] BacktestTrade model
- [ ] Strategy model

**Live Trading ihtiyacÄ±:**
- [ ] LiveTrade model
- [ ] Order model
- [ ] Position model

### Phase 3: Advanced Features (Uzun Vadeli)
- [ ] Alembic migrations (schema versioning)
- [ ] Repository pattern (clean CRUD separation)
- [ ] Bulk operations optimization
- [ ] Query performance tuning
- [ ] Data archival (old data cleanup)

---

## ğŸ” Database vs Parquet - Ne Zaman Hangisi?

### Database Kullan:
âœ… Real-time data (live trading positions)
âœ… Transactional data (orders, trades)
âœ… Recent data queries (last 100 trades)
âœ… Relational data (trade â†” orders)
âœ… WebUI dashboard (dynamic queries)

### Parquet Kullan:
âœ… Historical bulk data (years of OHLCV)
âœ… Backtest data (static datasets)
âœ… AI training datasets (millions of rows)
âœ… Analytics (indicator calculations)
âœ… Long-term archival (immutable history)

---

## ğŸ“ GeliÅŸtirme NotlarÄ±

### Yeni Model Eklemek:

**1. database_models.py'ye ekle:**
```python
from sqlalchemy import Column, Integer, String, Float, DateTime
from datetime import datetime

class Trade(Base):
    __tablename__ = "trades"

    id = Column(Integer, primary_key=True)
    symbol = Column(String(20), nullable=False, index=True)
    side = Column(String(10))  # LONG/SHORT
    entry_price = Column(Float)
    quantity = Column(Float)
    timestamp = Column(Integer, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)
```

**2. DatabaseEngine otomatik table oluÅŸturur:**
```python
await db.initialize()  # Base.metadata.create_all() otomatik Ã§alÄ±ÅŸÄ±r
```

**3. DatabaseManager'a CRUD ekle (opsiyonel):**
```python
async def save_trade(self, trade_data: dict) -> bool:
    """Trade kaydet"""
    async with self.get_session() as session:
        trade = Trade(**trade_data)
        session.add(trade)
        await session.commit()
    return True

async def get_trades(self, symbol: str, limit: int = 100) -> List[dict]:
    """Trade'leri getir"""
    async with self.get_session() as session:
        result = await session.execute(
            select(Trade)
            .where(Trade.symbol == symbol)
            .order_by(Trade.timestamp.desc())
            .limit(limit)
        )
        trades = result.scalars().all()
        return [{"symbol": t.symbol, "side": t.side, ...} for t in trades]
```

### Test Etme:
```bash
# Model test
python components/data/database_models.py

# DatabaseManager test
python components/data/database_manager.py

# DatabaseEngine test
python core/database_engine.py
```

---

## ğŸš¨ Ã–nemli Kurallar

### âœ… DO:
- Model eklemeden Ã¶nce **ihtiyaÃ§ olduÄŸundan emin ol**
- Tablolar **minimal** kalsÄ±n (gereksiz field ekleme)
- CRUD methodlarÄ± **lazy** ekle (kullanÄ±lacaÄŸÄ± zaman)
- Test et (her yeni model/method sonrasÄ±)

### âŒ DON'T:
- "Belki lazÄ±m olur" diye 40 tablo ekleme
- KullanÄ±lmayan field'lar ekleme
- WebUI-specific logic'i DatabaseManager'a taÅŸÄ±ma
- Repository pattern ÅŸimdilik YAPMA (over-engineering)

---

## ğŸ”— Ä°lgili Dosyalar

- `core/database_engine.py` - Database connection layer
- `config/infrastructure.yaml` - Database config
- `docs/plans/data_manager_implementation_plan.md` - DetaylÄ± plan (IGNORE - aÅŸÄ±rÄ± detaylÄ±)

---

**OluÅŸturuldu:** 2025-11-25
**Durum:** âœ… Base infrastructure hazÄ±r - Models/CRUD ihtiyaca gÃ¶re eklenecek
